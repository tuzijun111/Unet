{"cells":[{"metadata":{},"cell_type":"markdown","source":"### 240 Project: Clouds Patterns Detection"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport io\nimport math\nimport gc\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing:"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/understanding_cloud_organization'\nos.listdir(path)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(f'{path}/train.csv')\nsub = pd.read_csv(f'{path}/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_new = pd.DataFrame()\ntrain_new['img'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\ntrain_new['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\ntrain_new['EncodedPixels'] = train['EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.head(n=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train = len(os.listdir(f'{path}/train_images'))\nn_test = len(os.listdir(f'{path}/test_images'))\nprint(f'There are {n_train} images in train dataset')\nprint(f'There are {n_test} images in test dataset')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data distibution:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[1]).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.value_counts(train_new[['label','EncodedPixels']].dropna()['label']).plot('barh');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[0]).value_counts().value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution, how many figures we can find on one photo:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_new.dropna()[['img','label']].groupby(['img']).count().reset_index()['label'].hist();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize detection area and photos:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def detect(train_new, img):\n    image = plt.imread(f\"{path}/train_images/\" + img)\n    rle_string = train_new[(train_new['img']==img)]['EncodedPixels'].iloc[0]\n    rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n    rle_pairs = np.array(rle_numbers).reshape(-1,2)  # reshape to nx2\n    img = np.zeros(1400*2100, dtype=np.uint8)\n    for index, length in rle_pairs:\n        index -= 1\n        img[index:index+length] = 100\n    img = img.reshape(2100,1400)\n    np_mask = img.T\n    np_mask = np.clip(np_mask, 0, 1)\n    return np_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,25))\ndata_vis = train_new[train_new['label']=='Fish'].dropna()\nfor i in range(1,10):\n    fig.add_subplot(4,3,i)\n    mask = detect(data_vis , data_vis.iloc[i]['img'])\n    image = plt.imread(f\"{path}/train_images/\" + data_vis.iloc[i]['img'])\n    plt.imshow(image);\n    plt.imshow(mask, alpha=0.4);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mask Representation \n1. Label 0 or 1\n2. X coordinate of detection mask center \n3. Y coordinate of detection mask center\n4. Height of mask\n5. Width of mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create function that return height, width, x_center and y_center\ndef center_grad(label, np_mask):\n    \"\"\"This function return h, w, x_c, y_c of our mask\"\"\"\n    height = np.where(np_mask[:,:]==1)[0][-1]-np.where(np_mask[:,:]==1)[0][0]\n    width = np.where(np_mask[:,:]==1)[1][-1]-np.where(np_mask[:,:]==1)[1][0]\n    x_cen, y_cen = np.where(np_mask[:,:]==1)[0][0] + height//2, np.where(np_mask[:,:]==1)[1][0] + width//2\n    return label, x_cen, y_cen, height, width","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create special Fish,Flower,Gravel,Sugar groups for our network"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create special 'Fish' dataset \nfish_data = train_new[train_new['label']=='Fish']\nfish_data.set_index(np.arange(fish_data.shape[0]), inplace=True)\nfish_data['Label'] = fish_data['EncodedPixels'].apply(lambda x: 0 if pd.isnull(x) else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create special 'Flower' dataset \nflower_data = train_new[train_new['label']=='Flower']\nflower_data.set_index(np.arange(flower_data.shape[0]), inplace=True)\nflower_data['Label'] = flower_data['EncodedPixels'].apply(lambda x: 0 if pd.isnull(x) else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create special 'Gravel' dataset \ngravel_data = train_new[train_new['label']=='Gravel']\ngravel_data.set_index(np.arange(gravel_data.shape[0]), inplace=True)\ngravel_data['Label'] = gravel_data['EncodedPixels'].apply(lambda x: 0 if pd.isnull(x) else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create special 'Sugar' dataset \nsugar_data = train_new[train_new['label']=='Sugar']\nsugar_data.set_index(np.arange(sugar_data.shape[0]), inplace=True)\nsugar_data['Label'] = sugar_data['EncodedPixels'].apply(lambda x: 0 if pd.isnull(x) else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fish_data.head(n=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flower_data.head(n=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"height, width = 1400, 2100\ndef masks(train_new, name_image):\n    rle_string = train_new[train_new['img']==name_image]['EncodedPixels'].values[0]\n    if pd.isnull(rle_string):\n        return pd.DataFrame([])\n    else:\n        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n        img = np.zeros(height*width, dtype=np.uint8) #Return a new 1400*2100 filled with zeros.\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 100\n        img = img.reshape(height,width)\n        img = img.T\n\n        np_mask = img\n        np_mask = np.clip(np_mask, 0, 1)\n        return np_mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create DataLoader for this problem:"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CloudDataset(Dataset):\n    def __init__(self, df: pd.DataFrame = train_new, datatype: str = 'train', img_ids: np.array = None,\n                 transforms = transforms.ToTensor(),\n#                 transforms = transforms.Compose([transforms.Resize((256,256)), transforms.ToTensor()]),\n                preprocessing=None):\n        self.df = df\n        if datatype != 'test':\n            self.data_folder = f\"{path}/train_images\"\n        else:\n            self.data_folder = f\"{path}/test_images\"\n        self.transforms = transforms\n\n    def __getitem__(self, idx):\n        image_name = self.df['img'][idx]\n        mask = masks(self.df, image_name)\n        image_path = os.path.join(self.data_folder, image_name)\n        \n        image = Image.open(image_path)\n        image = self.transforms(image)\n        \n        if mask.shape != (0,0):\n            label = center_grad(self.df.iloc[idx]['Label'],mask)\n            if label[0] == 1:\n                label = (label[0], label[1]/height, label[2]/width,\n                            math.log(abs(label[3]+0.0001)), math.log(abs(label[4]+0.0001)) )\n        else: \n            label = (0,0,0,0,0)\n        return image, label\n    \n    def __len__(self):\n        return self.df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classes distribution in \"Fish dataset\""},{"metadata":{"trusted":true},"cell_type":"code","source":"fish_data[:100]['Label'].hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = CloudDataset(df=fish_data[:2000], datatype='train')\ntrain_loader = DataLoader(train_dataset, batch_size=1, shuffle=False, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n#         self.fc1 = nn.Linear(1*5*350*525, 5)\n        self.fc1 = nn.Linear(543402,5)     # 543402x5 array        #depend on the batch size\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5)\n        self.conv2 = nn.Conv2d(in_channels=5, out_channels=3, kernel_size=5)\n        \n    def forward(self,x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = x.view(-1)\n        x = self.fc1(x)\n        x = [F.sigmoid(x[0]),F.sigmoid(x[1]),F.sigmoid(x[2]),x[3],x[4]]\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create the main function for learning with pytorch. I'll learn only 10 epochs to save time."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlosses = []\n\n# define model\nmodel = Net()\nmodel = model.cuda()\ncrit_mse = nn.MSELoss()\ncrit_bce = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay=1e-5)\n\nfor epoch in range(1, 2):\n    print('epoch = ', epoch)\n    for batch_idx, (data, label) in enumerate(train_loader):\n            # get output\n            data = data.cuda()\n            for i in range(len(label)):\n                label[i] = label[i].cuda()\n            out = model(data)\n            \n            # transform output to our system\n            output = out\n            #loss = F.nll_loss(output, label)\n        \n            # define complex LOSS function\n            \n            #if label[0].item() == 1:\n                loss = crit_bce(output[0],torch.Tensor([label[0].item()]).cuda() ) + \\\n                     1*(crit_bce(output[1],torch.Tensor([label[1].item()]).cuda() ) +  \n                       crit_bce(output[2],torch.Tensor([label[2].item()]).cuda() ) + \\\n                       crit_mse(output[3],torch.Tensor([label[3].item()]).cuda() ) + \\\n                       crit_mse(output[4],torch.Tensor([label[4].item()]).cuda() ) )\n            else:\n                loss = crit_bce(output[0],torch.Tensor([label[0].item()]).cuda() )\n        \n                \n            if batch_idx % 500 == 0:\n                print('Loss :{:.4f} Epoch - {}/{}'.format(loss.item(), epoch, 10))\n            losses.append(loss)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            torch.cuda.empty_cache()\n    torch.cuda.empty_cache()\n    gc.collect()\n    del data\n    del label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss illustration for train dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(np.arange(len(losses)), losses);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare model prediction with target mask:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Helper function of Dice coefficient\ndef dice(img1, img2):\n    img1 = np.asarray(img1).astype(np.bool)\n    img2 = np.asarray(img2).astype(np.bool)\n\n    intersection = np.logical_and(img1, img2)\n\n    return 2. * intersection.sum() / (img1.sum() + img2.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = detect(data_vis , data_vis.iloc[0]['img'])\nimage = plt.imread(f\"{path}/train_images/\" + data_vis.iloc[0]['img'])\nplt.imshow(image);\nplt.imshow(mask, alpha=0.4);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = center_grad(1, mask)\nprint(ss[0], ss[1]/height, ss[2]/width, math.log(ss[3]), math.log(ss[4]))\nprint(ss[0], ss[1], ss[2], ss[3], ss[4])\n#print(dice(image, ss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = torch.Tensor(image.reshape(1,3,1400,2100)).cuda()\nmodel(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With same approach we can detect another categories. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub = pd.read_csv(f'{path}/sample_submission.csv')\n#test_dataset = CloudDataset(df=sub, datatype='test', img_ids=test_ids, transforms = get_validation_augmentation(), preprocessing=get_preprocessing(preprocessing_fn))\ntest_dataset = CloudDataset(df=sub, datatype='test')\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n\nloaders = {\"test\": test_loader}","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}